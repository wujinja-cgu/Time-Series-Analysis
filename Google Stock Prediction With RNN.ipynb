{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52458461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec520cd",
   "metadata": {},
   "source": [
    "### The First Step | Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8535b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdedb01",
   "metadata": {},
   "source": [
    "### The Second Step | preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c50e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Dataset\n",
    "Data = pd.read_csv(\"/kaggle/input/google-stock-prediction/GOOG.csv\")\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8249ff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking The Imported Dataset\n",
    "Data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e962e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geting Info\n",
    "Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame From Data\n",
    "df = pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing %h-%m-%s From Date Column\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['date'] = df['date'].dt.strftime('%d-%m-%Y')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf390d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking The Type Of Data Column(object)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f50fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Object To Datetime\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b961ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'symbol' Column From Dataset\n",
    "df.drop(columns= 'symbol', axis=1,inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92995999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking The Type Of Data Column(Datatime64) And Remove 'symbol' Column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03427896",
   "metadata": {},
   "source": [
    "### The Third Step | Visualization Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54534649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking distribution\n",
    "\n",
    "features = ['close', 'high', 'low', 'open', 'volume', 'adjClose', 'adjHigh', 'adjLow', 'adjOpen', 'adjVolume']\n",
    "sns.set_palette(\"PiYG\")\n",
    "plt.figure(figsize=(16,26))\n",
    "for idx, column in enumerate(features): \n",
    "    plt.subplot(5, 2, idx + 1)\n",
    "    sns.distplot(df, x=df[column], color='#75f8f2')\n",
    "    plt.title(column, backgroundcolor='black', color='orange', fontsize=25)\n",
    "    plt.xticks()\n",
    "    plt.xlabel(column, fontsize=16)\n",
    "    plt.ylabel('Density', fontsize=16)\n",
    "    plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking The Behavior Of Features In Relation To 'close'\n",
    "features = ['high', 'low', 'open', 'volume', 'adjClose', 'adjHigh', 'adjLow', 'adjOpen']\n",
    "sns.set_palette(\"PiYG\")\n",
    "plt.figure(figsize=(16,26))\n",
    "for idx, column in enumerate(features):\n",
    "    plt.subplot(5, 2,  idx + 1)\n",
    "    sns.scatterplot(x =df['close'], y=df[column] , data = df, color='orange')\n",
    "    plt.title(column, backgroundcolor='black', color='#75f8f2', fontsize=25)\n",
    "    plt.xlabel('Close', fontsize=16)\n",
    "    plt.ylabel(column, fontsize=16)\n",
    "    plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045d4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subplot\n",
    "features = ['close', 'high', 'low', 'open', 'volume', 'adjClose', 'adjHigh', 'adjLow', 'adjOpen', 'adjVolume']\n",
    "fig  = plt.subplots(nrows = 3, ncols = 3,figsize = (15,10))\n",
    "for i in range(len(features)) :\n",
    "    plt.subplot(2,5,i+1)\n",
    "    ax = sns.boxplot(df[features[i]], color=\"#75f8f2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8053db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new dataset For plot\n",
    "df1 = df.drop(['date', 'divCash', 'splitFactor'], axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3919963",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,25))\n",
    "for idx, i in enumerate(df1):\n",
    "    plt.subplot(8, 2, idx + 1)\n",
    "    plt.plot(df1.index.values,df1[i], color='#75f8f2')\n",
    "    plt.title(i,backgroundcolor='black',color='orange',fontsize=25)\n",
    "    plt.xlabel(i, size = 16)\n",
    "plt.tight_layout()                     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1af6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Style\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy from df\n",
    "df1= df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8279e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking and choosing the best time step\n",
    "ma_days = [5, 10, 20, 30, 60]\n",
    "\n",
    "for MA in ma_days:\n",
    "    column_name = f\"MA in {MA} days\"\n",
    "    df1[column_name] = df1['close'].rolling(MA).mean()   \n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "\n",
    "plt.plot(df1['date'],df1['close'],label='close')\n",
    "plt.plot(df1['date'],df1['MA in 5 days'],label= '5 days')\n",
    "plt.plot(df1['date'],df1['MA in 10 days'],label= '10 days')\n",
    "plt.plot(df1['date'],df1['MA in 20 days'],label= '20 days')\n",
    "plt.plot(df1['date'],df1['MA in 30 days'],label= '30 days')\n",
    "plt.plot(df1['date'],df1['MA in 60 days'],label= '60 days')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf697a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheking DataFram\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0571ab",
   "metadata": {},
   "source": [
    "### The Forth Step | Prepering dataset(Train, Test) to using in RNN Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a425d3",
   "metadata": {},
   "source": [
    "#### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae81d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy from df1\n",
    "df2= df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f526956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalaze Data For Create Trin and Test with new dataframe with only the 'Close' column \n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "# fit scaler on only one column('close')\n",
    "scaled = scaler.fit_transform(df2.filter(['close'])) \n",
    "# now have a scaled dataframe with 'colose column'\n",
    "df3=pd.DataFrame(scaled, columns=['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672bd077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get describe horizontally with '.T'\n",
    "df3.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6f09ac",
   "metadata": {},
   "source": [
    "#### Examining the divisions of Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17fe905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding a Length of %80 from the number of rows to Create a train Dataset (using array)\n",
    "new_dataset_length = int(np.ceil( len(df2.filter(['close']).values) * .8 )) \n",
    "print('Length of %80 of Dataset is ',new_dataset_length, ' Therefore, the test data length is ',len(df.close) - new_dataset_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292db9e7",
   "metadata": {},
   "source": [
    "#### Creating Train and Test from the column of 'close'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51376997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training data set with 20 time steps \n",
    "# finding the best time step from MA that 20 was the most optimal\n",
    "\n",
    "train = scaled[0:int(new_dataset_length), :]\n",
    "\n",
    "time_step = 20\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(time_step, len(train)):\n",
    "    X_train.append(train[i-time_step:i, 0])\n",
    "    y_train.append(train[i, 0])\n",
    "    if i<= (time_step+1):\n",
    "        print(X_train)\n",
    "        print(y_train)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b2847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the X_train and y_train to numpy arrays \n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9645f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the X_train \n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1701fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the test dataset\n",
    "test = scaled[new_dataset_length-time_step:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataSets of y_test\n",
    "y_test =  np.array(scaler.inverse_transform(df3))[new_dataset_length:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1835d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset of X_test\n",
    "X_test = []\n",
    "for i in range(time_step, len(test)):\n",
    "    X_test.append(test[i-time_step:i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf9ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dataset to a numpy array\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798912f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the data for learning in RNN model\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416833e4",
   "metadata": {},
   "source": [
    "### The fifth Step | Create Models of RNN base on LSTM, GRU, Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb26f9cf",
   "metadata": {},
   "source": [
    "#### Creating Model by LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat RNN\n",
    "RNN1 = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d36d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The First LSTM Layer\n",
    "RNN1.add(tf.keras.layers.LSTM(units=130, return_sequences=True, input_shape=(X_train.shape[1],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Second LSTM Layer\n",
    "RNN1.add(tf.keras.layers.LSTM(units=65, return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e7a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Connection\n",
    "RNN1.add(tf.keras.layers.Dense(units=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28443b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Output layer\n",
    "RNN1.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68b5980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling The RNN\n",
    "RNN1.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd358dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Model on The Train and Validation Dataset\n",
    "Model_1 = RNN1.fit(X_train, y_train,validation_data=(X_test, y_test), batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geting The Model Predicted Price Values \n",
    "predictions1 = RNN1.predict(X_test)\n",
    "# Converting scaled number to actual number\n",
    "predictions1 = scaler.inverse_transform(predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed55eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geting the score and error\n",
    "print(f'Mean Absolute Error: {metrics.mean_absolute_error(y_test, predictions1)}')\n",
    "print(f'Mean Squared Error: {metrics.mean_squared_error(y_test, predictions1)}')\n",
    "print(f'Root Mean Squared Error: {np.sqrt(metrics.mean_squared_error(y_test, predictions1))}')\n",
    "print(f'R2_Score: {metrics.r2_score(y_test, predictions1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be314de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change of style\n",
    "plt.style.use(\"seaborn-v0_8-muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab266706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and val data from DataFrame\n",
    "train = df2.filter(['close'])[:new_dataset_length]\n",
    "valid = df2.filter(['close'])[new_dataset_length:]\n",
    "valid['Predictions1'] = predictions1\n",
    "\n",
    "# Visualizing the data\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Model_1')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price', fontsize=18)\n",
    "plt.plot(df1['date'].iloc[:1007],train['close'])\n",
    "plt.plot(df1['date'].iloc[1007:],valid[['close', 'Predictions1']])\n",
    "plt.legend(['Train', 'Val', 'Predictions'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f681fd",
   "metadata": {},
   "source": [
    "#### Creating Model by GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d1ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat RNN\n",
    "RNN2 = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d9044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The First GRU Layer\n",
    "RNN2.add(tf.keras.layers.GRU(units=130, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ddf9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Second GRU Layer\n",
    "RNN2.add(tf.keras.layers.GRU(units=65, return_sequences=False, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefb52e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Connection\n",
    "RNN2.add(tf.keras.layers.Dense(units=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ebe01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Output layer\n",
    "RNN2.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling The RNN\n",
    "RNN2.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4405c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling The RNN\n",
    "RNN2.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c77b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Model on The Train and Validation Dataset\n",
    "Model_2 = RNN2.fit(X_train, y_train,validation_data=(X_test, y_test), batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geting The Model Predicted Price Values \n",
    "predictions2 = RNN2.predict(X_test)\n",
    "# Converting scaled number to actual number\n",
    "predictions2 = scaler.inverse_transform(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d609e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geting the score and error\n",
    "print(f'Mean Absolute Error: {metrics.mean_absolute_error(y_test, predictions2)}')\n",
    "print(f'Mean Squared Error: {metrics.mean_squared_error(y_test, predictions2)}')\n",
    "print(f'Root Mean Squared Error: {np.sqrt(metrics.mean_squared_error(y_test, predictions2))}')\n",
    "print(f'R2_Score: {metrics.r2_score(y_test, predictions2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383746c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and val data from DataFrame\n",
    "train = df2.filter(['close'])[:new_dataset_length]\n",
    "valid = df2.filter(['close'])[new_dataset_length:]\n",
    "valid['Predictions2'] = predictions2\n",
    "\n",
    "# Visualizing the data\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Model_2')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price', fontsize=18)\n",
    "plt.plot(df1['date'].iloc[:1007],train['close'])\n",
    "plt.plot(df1['date'].iloc[1007:],valid[['close', 'Predictions2']])\n",
    "plt.legend(['Train', 'Val', 'Predictions'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa89fbf",
   "metadata": {},
   "source": [
    "#### Creating Model by LSTM & Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat RNN\n",
    "RNN3 = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The First Bidirectional & LSTM  Layer\n",
    "RNN3.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=130, return_sequences=True, input_shape=(X_train.shape[1],1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf37235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Second Bidirectional & LSTM Layer\n",
    "RNN3.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=65, return_sequences=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9388b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Connection\n",
    "RNN3.add(tf.keras.layers.Dense(units=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aa3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Output layer\n",
    "RNN3.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d739c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling The RNN\n",
    "RNN3.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c1f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Model on The Train and Validation Dataset\n",
    "Model_3 = RNN2.fit(X_train, y_train,validation_data=(X_test, y_test), batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b5120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geting The Models Predicted Price Values \n",
    "predictions3 = RNN3.predict(X_test)\n",
    "# Converting scaled number to actual number\n",
    "predictions3 = scaler.inverse_transform(predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25edb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geting the score and error\n",
    "print(f'Mean Absolute Error: {metrics.mean_absolute_error(y_test, predictions3)}')\n",
    "print(f'Mean Squared Error: {metrics.mean_squared_error(y_test, predictions3)}')\n",
    "print(f'Root Mean Squared Error: {np.sqrt(metrics.mean_squared_error(y_test, predictions3))}')\n",
    "print(f'R2_Score: {metrics.r2_score(y_test, predictions3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad73b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and val data from DataFrame\n",
    "train = df2.filter(['close'])[:new_dataset_length]\n",
    "valid = df2.filter(['close'])[new_dataset_length:]\n",
    "valid['Predictions3'] = predictions3\n",
    "\n",
    "# Visualizing the data\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Model_3')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price', fontsize=18)\n",
    "plt.plot(df1['date'].iloc[:1007],train['close'])\n",
    "plt.plot(df1['date'].iloc[1007:],valid[['close', 'Predictions3']])\n",
    "plt.legend(['Train', 'Val', 'Predictions'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c96125",
   "metadata": {},
   "source": [
    "#### Creating Model by LSTM & GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfddcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat RNN\n",
    "RNN4 = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0961e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The First Layer of LSTM \n",
    "RNN4.add(tf.keras.layers.LSTM(units=130, return_sequences=True, input_shape=(X_train.shape[1],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c228ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Second Layer of GRU \n",
    "RNN4.add(tf.keras.layers.GRU(units=65, return_sequences=False, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88528b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Connection\n",
    "RNN4.add(tf.keras.layers.Dense(units=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb92cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Output layer\n",
    "RNN4.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237acad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling The RNN\n",
    "RNN4.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1dd322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Model on The Train and Validation Dataset\n",
    "Model_4 = RNN4.fit(X_train, y_train,validation_data=(X_test, y_test), batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca232dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geting The Models Predicted Price Values \n",
    "predictions4 = RNN4.predict(X_test)\n",
    "# Converting scaled number to actual number\n",
    "predictions4 = scaler.inverse_transform(predictions4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb41d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geting the score and error\n",
    "print(f'Mean Absolute Error: {metrics.mean_absolute_error(y_test, predictions4)}')\n",
    "print(f'Mean Squared Error: {metrics.mean_squared_error(y_test, predictions4)}')\n",
    "print(f'Root Mean Squared Error: {np.sqrt(metrics.mean_squared_error(y_test, predictions4))}')\n",
    "print(f'R2_Score: {metrics.r2_score(y_test, predictions4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d068da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and val data from DataFrame\n",
    "train = df2.filter(['close'])[:new_dataset_length]\n",
    "valid = df2.filter(['close'])[new_dataset_length:]\n",
    "valid['Predictions4'] = predictions4\n",
    "\n",
    "# Visualizing the data\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Model_4')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price', fontsize=18)\n",
    "plt.plot(df1['date'].iloc[:1007],train['close'])\n",
    "plt.plot(df1['date'].iloc[1007:],valid[['close', 'Predictions4']])\n",
    "plt.legend(['Train', 'Val', 'Predictions'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c2453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all of Models for WebApp or other predictions\n",
    "joblib.dump(Model_1, 'model1')\n",
    "joblib.dump(Model_2, 'model2') # The best model\n",
    "joblib.dump(Model_4, 'model4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
